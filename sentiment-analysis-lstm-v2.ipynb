{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import load_corpus, stopwords, processing\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "import os\n",
    "import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today().strftime('%Y%m%d')\n",
    "if not os.path.exists('./evaluation/lstm/{}'.format(today)):\n",
    "    os.makedirs('./evaluation/lstm/{}'.format(today))\n",
    "writer = SummaryWriter(log_dir=os.path.join('./evaluation/lstm', today))\n",
    "\n",
    "if not os.path.exists('./model/classification/lstm/{}'.format(today)):\n",
    "    os.makedirs('./model/classification/lstm/{}'.format(today))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('../Dataset/weibo_senti_120k_train.csv') \n",
    "df_test=pd.read_csv('../Dataset/weibo_senti_120k_test.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    19783\n",
       "0    19364\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.617 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "# 预处理\n",
    "df_train['text_split'] = df_train['text'].apply(lambda x: processing(x))\n",
    "df_test['text_split'] = df_test['text'].apply(lambda x: processing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                        我 想 看 啊 求 sponsor\n",
       "1                                             我 靠 这 是 什么 ！\n",
       "2                                                从 烟花 中来 ？\n",
       "3        和 某些 搞 艺术 的 人 聊天 上 一秒 想 骂 傻 X 下 一秒 还算赞 总之 跌倒 起...\n",
       "4                                                   外国 绕口令\n",
       "                               ...                        \n",
       "91336    中国 有 自古 句 俗话 叫 隐恶扬善 足够 解释 王局 的 困惑 了 用 现在 官方 主流...\n",
       "91337                                       解散 彻底 解散 ！ ！ ！\n",
       "91338                                                   回复\n",
       "91339                      这么 早 回家 真是 不可思议 这 可是 周六 呀 ！ ！ ！\n",
       "91340    我 的 黑米 啊 不知道 你 想 不想 我 还 记得 我 抱 你 回家 的 时候 转眼 6 ...\n",
       "Name: text_split, Length: 91341, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['text_split']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                             [我, 想, 看, 啊, 求, sponsor]\n",
       "1                                  [我, 靠, 这, 是, 什么, ！]\n",
       "2                                       [从, 烟花, 中来, ？]\n",
       "3    [和, 某些, 搞, 艺术, 的, 人, 聊天, 上, 一秒, 想, 骂, 傻, X, 下,...\n",
       "4                                            [外国, 绕口令]\n",
       "Name: text_split, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word2vec要求的输入格式: list(word)\n",
    "wv_input = df_train['text_split'].map(lambda s: s.split(\" \"))   # [for w in s.split(\" \") if w not in stopwords]\n",
    "wv_input.head()          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/june_env/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim import models\n",
    "\n",
    "# Word2Vec\n",
    "word2vec = models.Word2Vec(wv_input, \n",
    "                           vector_size=100,   # 词向量维度\n",
    "                           min_count=1,      # 最小词频, 因为数据量较小, 这里卡1\n",
    "                           epochs=1000)      # 迭代轮次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec.save('model/word/word2vec_120k_without_emo.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".molde load time 1.1300\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t1 = time.time()\n",
    "word2vec = models.Word2Vec.load('model/word/word2vec_120k.model')\n",
    "t2 = time.time()\n",
    "print(\".molde load time %.4f\"%(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('我', 0.9386610984802246),\n",
       " ('他', 0.853631854057312),\n",
       " ('你们', 0.8486167192459106),\n",
       " ('她', 0.8248060345649719),\n",
       " ('自己', 0.8246130347251892),\n",
       " ('他们', 0.7918105721473694),\n",
       " ('的', 0.7791113257408142),\n",
       " ('了', 0.774533212184906),\n",
       " ('我们', 0.7697728872299194),\n",
       " ('？', 0.7607975006103516)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar(\"你\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('伤心', 0.4740165174007416),\n",
       " ('伤感', 0.4664136469364166),\n",
       " ('心酸', 0.4656721353530884),\n",
       " ('事情', 0.4350576102733612),\n",
       " ('感人', 0.42465442419052124),\n",
       " ('忧伤', 0.4231449365615845),\n",
       " ('沉默', 0.4070686399936676),\n",
       " ('发生', 0.39861395955085754),\n",
       " ('世间', 0.3984120488166809),\n",
       " ('事', 0.396019846200943)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.wv.most_similar(\"悲伤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 情绪词典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/root/nas/chinese-sentiment-analysis/data/negative-words.txt', encoding='utf-8') as f:\n",
    "    negative_words = f.read().splitlines() \n",
    "with open('/root/nas/chinese-sentiment-analysis/data/positive-words.txt', encoding='utf-8') as f:\n",
    "    positive_words = f.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence,pad_packed_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数\n",
    "learning_rate = 5e-4\n",
    "input_size = 768\n",
    "num_epoches = 20\n",
    "batch_size = 128\n",
    "embed_size = 100\n",
    "hidden_size = 64\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据集\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.data = []\n",
    "        self.emo = []\n",
    "        self.label = df[\"label\"].tolist()\n",
    "        # 注意这里，别取错列了！！\n",
    "        for s in df[\"text_split\"].tolist():\n",
    "            vectors = []\n",
    "            for w in s.split(\" \"):\n",
    "                if w in word2vec.wv.key_to_index:\n",
    "                    vectors.append(word2vec.wv[w])   # 将每个词替换为对应的词向量\n",
    "                else:\n",
    "                    vectors.append([0]*embed_size)\n",
    "                \n",
    "                \n",
    "            vectors = torch.Tensor(vectors)\n",
    "            # Lexicon Embedding\n",
    "            emo_encoded = torch.Tensor([2 if word in positive_words else 1 if word in negative_words else 0 for word in s.split(\" \") ])\n",
    "            self.data.append(vectors)\n",
    "            self.emo.append(emo_encoded)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.data[index]\n",
    "        emo = self.emo[index]\n",
    "        label = self.label[index]\n",
    "        return data, emo, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "\n",
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    :param data: 第0维：data，第1维：emo情绪词，第2维：label\n",
    "    :return: 序列化的data、记录实际长度的序列、以及label列表\n",
    "    \"\"\"\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True) # pack_padded_sequence要求要按照序列的长度倒序排列\n",
    "    data_length = [len(sq[0]) for sq in data]\n",
    "    x1 = [i[0] for i in data]\n",
    "    x2 = [i[1] for i in data]\n",
    "    y = [i[2] for i in data]\n",
    "\n",
    "    data = pad_sequence(x1, batch_first=True, padding_value=0)   # 用RNN处理变长序列的必要操作\n",
    "    emo = pad_sequence(x2, batch_first=True, padding_value=0)   # 用RNN处理变长序列的必要操作\n",
    "    return data, emo, torch.tensor(y, dtype=torch.float32), torch.tensor(data_length)\n",
    "\n",
    "\n",
    "# 训练集\n",
    "train_data = MyDataset(df_train)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "\n",
    "# 测试集\n",
    "test_data = MyDataset(df_test)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, collate_fn=collate_fn, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络结构\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)  # 双向, 输出维度要*2\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x1, x2, lengths):\n",
    "        x = torch.cat((x2.unsqueeze(-1),x1),2)  \n",
    "        # x = x1\n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)  # 双向, 第一个维度要*2\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "        packed_input = torch.nn.utils.rnn.pack_padded_sequence(input=x, lengths=lengths, batch_first=True)\n",
    "        packed_out, (h_n, h_c) = self.lstm(packed_input, (h0, c0))\n",
    "\n",
    "        lstm_out = torch.cat([h_n[-2], h_n[-1]], 1)  # 双向, 所以要将最后两维拼接, 得到的就是最后一个time step的输出\n",
    "        out = self.fc(lstm_out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "lstm = LSTM(embed_size+1, hidden_size, num_layers).to(device)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "# 在测试集效果检验\n",
    "def test(epoch,num_epoches):\n",
    "    y_pred, y_true = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, emo, labels, lengths in test_loader:\n",
    "            x = x.to(device)\n",
    "            emo = emo.to(device)\n",
    "            outputs = lstm(x,emo, lengths)         # 前向传播\n",
    "            outputs = outputs.view(-1)          # 将输出展平\n",
    "            y_pred.append(outputs)\n",
    "            y_true.append(labels)\n",
    "\n",
    "    y_prob = torch.cat(y_pred).cpu()\n",
    "    y_true = torch.cat(y_true).cpu()\n",
    "    y_pred = y_prob.clone()\n",
    "    y_pred[y_pred > 0.5] = 1\n",
    "    y_pred[y_pred <= 0.5] = 0\n",
    "    \n",
    "    precision, recall, f1, _ = metrics.precision_recall_fscore_support(y_true, y_pred)\n",
    "    roc_auc = metrics.roc_auc_score(y_true, y_prob)\n",
    "    print('Epoch {}/{}, P {:.4f}, R {:.4f}, F1 {:.4f}, AUC {:.4f}'.format(\n",
    "        epoch, num_epoches, precision.mean(), recall.mean(), f1.mean(), roc_auc.mean()))\n",
    "    writer.add_scalar('precision', precision.mean(), epoch)\n",
    "    writer.add_scalar('recall', recall.mean(), epoch)\n",
    "    writer.add_scalar('f1score', f1.mean(), epoch)\n",
    "    writer.add_scalar('auc', roc_auc.mean(), epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1, step:500, loss:28.236026763916016\n",
      "Epoch 0/20, P 0.7188, R 0.7145, F1 0.7135, AUC 0.7956\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_1.model\n",
      "epoch:2, step:500, loss:26.20993995666504\n",
      "Epoch 1/20, P 0.7212, R 0.7197, F1 0.7196, AUC 0.8014\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_2.model\n",
      "epoch:3, step:500, loss:25.227643966674805\n",
      "Epoch 2/20, P 0.7242, R 0.7200, F1 0.7192, AUC 0.8024\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_3.model\n",
      "epoch:4, step:500, loss:23.93129539489746\n",
      "Epoch 3/20, P 0.7237, R 0.7188, F1 0.7178, AUC 0.8018\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_4.model\n",
      "epoch:5, step:500, loss:22.52192497253418\n",
      "Epoch 4/20, P 0.7182, R 0.7151, F1 0.7145, AUC 0.7947\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_5.model\n",
      "epoch:6, step:500, loss:20.962766647338867\n",
      "Epoch 5/20, P 0.7126, R 0.7076, F1 0.7064, AUC 0.7888\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_6.model\n",
      "epoch:7, step:500, loss:19.61814308166504\n",
      "Epoch 6/20, P 0.7048, R 0.7038, F1 0.7036, AUC 0.7780\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_7.model\n",
      "epoch:8, step:500, loss:18.14410972595215\n",
      "Epoch 7/20, P 0.7025, R 0.6992, F1 0.6983, AUC 0.7736\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_8.model\n",
      "epoch:9, step:500, loss:16.72893714904785\n",
      "Epoch 8/20, P 0.6975, R 0.6967, F1 0.6966, AUC 0.7695\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_9.model\n",
      "epoch:10, step:500, loss:15.441725730895996\n",
      "Epoch 9/20, P 0.6918, R 0.6906, F1 0.6904, AUC 0.7610\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_10.model\n",
      "epoch:11, step:500, loss:14.23180866241455\n",
      "Epoch 10/20, P 0.6859, R 0.6851, F1 0.6850, AUC 0.7535\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_11.model\n",
      "epoch:12, step:500, loss:13.259383201599121\n",
      "Epoch 11/20, P 0.6840, R 0.6834, F1 0.6833, AUC 0.7505\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_12.model\n",
      "epoch:13, step:500, loss:12.236783981323242\n",
      "Epoch 12/20, P 0.6793, R 0.6776, F1 0.6772, AUC 0.7437\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_13.model\n",
      "epoch:14, step:500, loss:11.612869262695312\n",
      "Epoch 13/20, P 0.6800, R 0.6776, F1 0.6768, AUC 0.7445\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_14.model\n",
      "epoch:15, step:500, loss:10.647974967956543\n",
      "Epoch 14/20, P 0.6800, R 0.6794, F1 0.6794, AUC 0.7460\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_15.model\n",
      "epoch:16, step:500, loss:10.196533203125\n",
      "Epoch 15/20, P 0.6783, R 0.6750, F1 0.6740, AUC 0.7382\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_16.model\n",
      "epoch:17, step:500, loss:9.814034461975098\n",
      "Epoch 16/20, P 0.6811, R 0.6788, F1 0.6781, AUC 0.7432\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_17.model\n",
      "epoch:18, step:500, loss:9.19788932800293\n",
      "Epoch 17/20, P 0.6760, R 0.6742, F1 0.6737, AUC 0.7386\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_18.model\n",
      "epoch:19, step:500, loss:8.670924186706543\n",
      "Epoch 18/20, P 0.6721, R 0.6719, F1 0.6719, AUC 0.7376\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_19.model\n",
      "epoch:20, step:500, loss:8.327836990356445\n",
      "Epoch 19/20, P 0.6764, R 0.6737, F1 0.6729, AUC 0.7398\n",
      "saved model:  ./model/classification/lstm/20220303/lstm_120k_20.model\n"
     ]
    }
   ],
   "source": [
    "# 迭代训练\n",
    "for epoch in range(num_epoches):\n",
    "    total_loss = 0\n",
    "    for i, (x,emo, labels, lengths) in enumerate(train_loader):\n",
    "        x = x.to(device)\n",
    "        emo = emo.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = lstm(x, emo, lengths)          # 前向传播\n",
    "        logits = outputs.view(-1)           # 将输出展平\n",
    "        loss = criterion(logits, labels)    # loss计算\n",
    "        total_loss += loss\n",
    "        optimizer.zero_grad()               # 梯度清零\n",
    "        loss.backward(retain_graph=True)    # 反向传播，计算梯度\n",
    "        optimizer.step()                    # 梯度更新\n",
    "        if (i+1) % 500 == 0:\n",
    "            print(\"epoch:{}, step:{}, loss:{}\".format(epoch+1, i+1, total_loss/10))\n",
    "            total_loss = 0\n",
    "    writer.add_scalar('train_loss', total_loss, epoch)\n",
    "    # test\n",
    "    test(epoch,num_epoches)\n",
    "    \n",
    "    # save model\n",
    "    model_path = \"./model/classification/lstm/{}/lstm_120k_{}.model\".format(today,epoch+1)\n",
    "    torch.save(lstm, model_path)\n",
    "    print(\"saved model: \", model_path)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '一声', '龙啸', '凌云志', '！', '热血', '燃冬', '扶摇', '起', '！']\n",
      "['这么', '大', '个人', '了', '不嫌', '丢人', '？', '一点', '素质', '也', '没有']\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2286980/3430244405.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2286980/2666570362.py\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 用RNN处理变长序列的必要操作\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_2286980/2666570362.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 用RNN处理变长序列的必要操作\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "from utils import processing\n",
    "\n",
    "strs = [\"我想说我会爱你多一点点\", \"日有所思梦感伤\"]\n",
    "strs = [\"我一声龙啸凌云志！热血燃冬扶摇起！\",\"这么大个人了，不嫌丢人？一点素质也没有\"]\n",
    "\n",
    "data = []\n",
    "for s in strs:\n",
    "    vectors = []\n",
    "    print(processing(s).split(\" \"))\n",
    "    for w in processing(s).split(\" \"):\n",
    "        if w in word2vec.wv.key_to_index:\n",
    "            vectors.append(word2vec.wv[w])   # 将每个词替换为对应的词向量\n",
    "    vectors = torch.Tensor(vectors)\n",
    "    data.append(vectors)\n",
    "\n",
    "x, _, lengths = collate_fn(list(zip(data, [-1] * len(strs))))\n",
    "with torch.no_grad():\n",
    "    x = x.to(device)\n",
    "    outputs = lstm(x, lengths)       # 前向传播\n",
    "    outputs = outputs.view(-1)          # 将输出展平\n",
    "outputs.cpu()[0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from utils import processing\n",
    "\n",
    "# 超参数\n",
    "embed_size = 100\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "# 需先搭建网络模型model\n",
    "# 网络结构\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, 1)  # 双向, 输出维度要*2\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x1, x2, lengths):\n",
    "        x = torch.cat((x2.unsqueeze(-1),x1),2)  \n",
    "        h0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)  # 双向, 第一个维度要*2\n",
    "        c0 = torch.zeros(self.num_layers * 2, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        packed_input = torch.nn.utils.rnn.pack_padded_sequence(input=x, lengths=lengths, batch_first=True)\n",
    "        \n",
    "        packed_out, (h_n, h_c) = self.lstm(packed_input, (h0, c0))\n",
    "\n",
    "        lstm_out = torch.cat([h_n[-2], h_n[-1]], 1)  # 双向, 所以要将最后两维拼接, 得到的就是最后一个time step的输出\n",
    "        out = self.fc(lstm_out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "lstm = LSTM(embed_size+1, hidden_size, num_layers).to(device)   \n",
    "# 然后通过下面的语句加载参数\n",
    "# lstm_new = model.load_state_dict(torch.load('model/classification/lstm_10k_7.model'))\n",
    "lstm=torch.load('model/classification/lstm_10k_7.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from gensim import models\n",
    "t1 = time.time()\n",
    "word2vec = models.Word2Vec.load('model/word/word2vec_10k.model')\n",
    "t2 = time.time()\n",
    "print(\".molde load time %.4f\"%(t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(data):\n",
    "    \"\"\"\n",
    "    :param data: 第0维：data，第1维：label\n",
    "    :return: 序列化的data、记录实际长度的序列、以及label列表\n",
    "    \"\"\"\n",
    "    data.sort(key=lambda x: len(x[0]), reverse=True) # pack_padded_sequence要求要按照序列的长度倒序排列\n",
    "    data_length = [len(sq[0]) for sq in data]\n",
    "    x = [i[0] for i in data]\n",
    "    y = [i[1] for i in data]\n",
    "\n",
    "    data = pad_sequence(x, batch_first=True, padding_value=0)   # 用RNN处理变长序列的必要操作\n",
    "    return data, torch.tensor(y, dtype=torch.float32), torch.tensor(data_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_emo_score(text):\n",
    "    vectors= []\n",
    "    for w in processing(text).split(\" \"):\n",
    "        if w in word2vec.wv.key_to_index:\n",
    "            vectors.append(word2vec.wv[w])   # 将每个词替换为对应的词向量\n",
    "    vectors = torch.Tensor(vectors)\n",
    "    x, _, lengths = collate_fn(list(zip([vectors], [-1])))\n",
    "    if lengths[0].item()<1:\n",
    "        return None\n",
    "    with torch.no_grad():\n",
    "        x = x.to(device)\n",
    "        outputs = lstm(x, lengths)       # 前向传播\n",
    "        outputs = outputs.view(-1)    # 将输出展平\n",
    "        result_score = outputs.cpu()[0].item()      \n",
    "    return result_score\n",
    "\n",
    "# 验证\n",
    "crawl_result = pd.read_csv('../Dataset/crawl_result.csv')\n",
    "crawl_result['emo_score'] = crawl_result['texts'].apply(lambda x: calculate_emo_score(x))\n",
    "crawl_result.to_csv('result/crawl_result_emo.csv', index=False, encoding='utf-8-sig')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f206eec9635af0142f17963922b2c01bd4f5db146619bf95f2cce0426ba31334"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('torch1.10': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
